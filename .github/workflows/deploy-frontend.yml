# .github/workflows/deploy-frontend.yml
name: Deploy Frontend to Google Cloud Storage

on:
  push:
    branches: [main]
    paths: ['frontend/**']
  workflow_dispatch:

env:
  PROJECT_ID: bunklogsauth
  FRONTEND_BUCKET: bunk-logs-frontend-prod

jobs:
  test-frontend:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: './frontend/package-lock.json'

      - name: Install dependencies
        working-directory: ./frontend
        run: npm ci

      - name: Run tests (if any)
        working-directory: ./frontend
        run: |
          if npm run test --if-present; then
            echo "✅ Frontend tests passed"
          else
            echo "ℹ️ No tests found or tests failed"
          fi

  deploy-frontend:
    needs: test-frontend
    runs-on: ubuntu-latest
    environment: production
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: './frontend/package-lock.json'

      - name: Install dependencies
        working-directory: ./frontend
        run: npm ci

      - name: Build frontend
        working-directory: ./frontend
        env:
          VITE_API_URL: ${{ secrets.RENDER_BACKEND_URL || 'https://admin.bunklogs.net' }}
          VITE_GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID }}
        run: npm run build

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.PROJECT_ID }}

      # CRITICAL: Invalidate cache BEFORE deployment
      - name: Pre-deployment cache invalidation
        run: |
          echo "🔄 Pre-invalidating CDN cache to prevent stale content..."
          gcloud compute url-maps invalidate-cdn-cache bunk-logs-frontend-map \
            --path="/*" \
            --global || echo "⚠️ Pre-invalidation failed, continuing..."

      - name: Create frontend bucket if not exists
        run: |
          gsutil ls gs://${{ env.FRONTEND_BUCKET }} || \
          (
            echo "📦 Creating new frontend bucket..."
            gsutil mb gs://${{ env.FRONTEND_BUCKET }}
            gsutil web set -m index.html -e 404.html gs://${{ env.FRONTEND_BUCKET }}
            gsutil iam ch allUsers:objectViewer gs://${{ env.FRONTEND_BUCKET }}
            echo "✅ Frontend bucket created and configured"
          )

      # IMPROVED: Deploy with atomic-like behavior
      - name: Deploy frontend to Cloud Storage (Atomic)
        working-directory: ./frontend
        run: |
          echo "🚀 Deploying frontend with atomic-like behavior..."
          
          # Create a temporary "staging" directory in the bucket
          TEMP_DIR="_staging_$(date +%s)"
          
          # Upload to staging directory first
          echo "📤 Uploading to staging directory: $TEMP_DIR"
          gsutil -m cp -r dist/* "gs://${{ env.FRONTEND_BUCKET }}/$TEMP_DIR/"
          
          # Verify upload completed successfully
          echo "🔍 Verifying upload completion..."
          
          # List what we're trying to upload locally
          echo "📋 Local dist contents:"
          find dist -type f | head -10
          
          STAGING_COUNT=$(gsutil ls -r "gs://${{ env.FRONTEND_BUCKET }}/$TEMP_DIR/" | wc -l)
          LOCAL_COUNT=$(find dist -type f | wc -l)
          
          echo "Local files: $LOCAL_COUNT, Uploaded files: $STAGING_COUNT"
          
          # Show what was actually uploaded
          echo "📋 Staging directory contents:"
          gsutil ls -r "gs://${{ env.FRONTEND_BUCKET }}/$TEMP_DIR/" | head -10
          
          if [ "$STAGING_COUNT" -ge "$LOCAL_COUNT" ]; then
            echo "✅ Upload verification passed"
            
            # Now move files from staging to root (this handles subdirectories properly)
            echo "🔄 Moving files from staging to production..."
            gsutil -m cp -r "gs://${{ env.FRONTEND_BUCKET }}/$TEMP_DIR/*" "gs://${{ env.FRONTEND_BUCKET }}/"
            gsutil -m rm -r "gs://${{ env.FRONTEND_BUCKET }}/$TEMP_DIR/"
            
            # Verify final deployment
            echo "🔍 Verifying final deployment..."
            gsutil ls "gs://${{ env.FRONTEND_BUCKET }}/index.html" && echo "✅ index.html found"
            gsutil ls "gs://${{ env.FRONTEND_BUCKET }}/assets/" && echo "✅ assets/ directory found" || echo "⚠️ assets/ directory missing"
            
            echo "✅ Atomic deployment complete"
          else
            echo "❌ Upload verification failed"
            gsutil rm -r "gs://${{ env.FRONTEND_BUCKET }}/$TEMP_DIR/" || echo "Cleanup failed"
            exit 1
          fi

      # IMPROVED: More aggressive cache headers management
      - name: Set optimized cache headers
        run: |
          echo "📝 Setting optimized cache headers..."
          
          # Set long cache for hashed assets (Vite automatically adds hashes)
          echo "🔧 Setting 1-year cache for hashed assets..."
          gsutil -m setmeta -h "Cache-Control:public, max-age=31536000, immutable" \
            "gs://${{ env.FRONTEND_BUCKET }}/assets/**" 2>/dev/null || echo "No assets directory found"
          
          # Set short cache for HTML files to ensure fresh content
          echo "🔧 Setting 5-minute cache for HTML files..."
          gsutil -m setmeta -h "Cache-Control:public, max-age=300, must-revalidate" \
            "gs://${{ env.FRONTEND_BUCKET }}/index.html"
          
          # Set medium cache for other static files
          echo "🔧 Setting 1-hour cache for other static files..."
          gsutil -m setmeta -h "Cache-Control:public, max-age=3600" \
            "gs://${{ env.FRONTEND_BUCKET }}/*.js" \
            "gs://${{ env.FRONTEND_BUCKET }}/*.css" \
            "gs://${{ env.FRONTEND_BUCKET }}/*.ico" \
            "gs://${{ env.FRONTEND_BUCKET }}/*.png" \
            "gs://${{ env.FRONTEND_BUCKET }}/*.jpg" \
            "gs://${{ env.FRONTEND_BUCKET }}/*.svg" 2>/dev/null || echo "Some static files not found"

      - name: Setup Cloud CDN (if not exists)
        run: |
          if ! gcloud compute backend-buckets describe bunk-logs-frontend-backend --global 2>/dev/null; then
            echo "🌐 Setting up Cloud CDN with SPA routing..."
            
            gcloud compute backend-buckets create bunk-logs-frontend-backend \
              --gcs-bucket-name=${{ env.FRONTEND_BUCKET }} || echo "Backend bucket may already exist"
            
            gcloud compute url-maps create bunk-logs-frontend-map \
              --default-backend-bucket=bunk-logs-frontend-backend \
              --global || echo "URL map may already exist"
            
            # Add path matcher for SPA routing
            gcloud compute url-maps add-path-matcher bunk-logs-frontend-map \
              --path-matcher-name=spa-matcher \
              --default-backend-bucket=bunk-logs-frontend-backend \
              --path-rules="/,/assets/*,/favicon.ico,/robots.txt,/manifest.json:bunk-logs-frontend-backend" \
              --global || echo "Path matcher already exists"
            
            gcloud compute ssl-certificates create bunk-logs-frontend-ssl \
              --domains=clc.bunklogs.net \
              --global || echo "SSL certificate may already exist"
            
            gcloud compute target-https-proxies create bunk-logs-frontend-proxy \
              --url-map=bunk-logs-frontend-map \
              --ssl-certificates=bunk-logs-frontend-ssl \
              --global || echo "HTTPS proxy may already exist"
            
            gcloud compute forwarding-rules create bunk-logs-frontend-forwarding-rule \
              --global \
              --target-https-proxy=bunk-logs-frontend-proxy \
              --ports=443 || echo "Forwarding rule may already exist"
            
            echo "✅ CDN setup complete!"
            
            LB_IP=$(gcloud compute forwarding-rules describe bunk-logs-frontend-forwarding-rule --global --format="get(IPAddress)" || echo "Could not retrieve IP")
            if [ "$LB_IP" != "Could not retrieve IP" ]; then
              echo "🌐 Load Balancer IP: $LB_IP"
              echo "📋 DNS Configuration Required:"
              echo "   Create an A record for clc.bunklogs.net pointing to: $LB_IP"
            fi
            
          else
            echo "✅ CDN already exists, skipping setup."
            LB_IP=$(gcloud compute forwarding-rules describe bunk-logs-frontend-forwarding-rule --global --format="get(IPAddress)" 2>/dev/null || echo "Could not retrieve IP")
            if [ "$LB_IP" != "Could not retrieve IP" ]; then
              echo "🌐 Current Load Balancer IP: $LB_IP"
            fi
          fi

      # CRITICAL: Multiple cache invalidation attempts
      - name: Aggressive cache invalidation
        run: |
          echo "🔄 Performing aggressive cache invalidation..."
          
          # Primary invalidation
          if gcloud compute url-maps invalidate-cdn-cache bunk-logs-frontend-map \
            --path="/*" \
            --global; then
            echo "✅ Primary cache invalidation successful"
          else
            echo "❌ Primary cache invalidation failed"
          fi
          
          # Wait and retry specific paths
          sleep 10
          
          echo "🔄 Invalidating specific critical paths..."
          gcloud compute url-maps invalidate-cdn-cache bunk-logs-frontend-map \
            --path="/index.html" \
            --global || echo "Index invalidation failed"
          
          gcloud compute url-maps invalidate-cdn-cache bunk-logs-frontend-map \
            --path="/assets/*" \
            --global || echo "Assets invalidation failed"
          
          # Final verification wait
          echo "⏳ Waiting 30 seconds for cache propagation..."
          sleep 30

      - name: Enhanced health check with retry
        run: |
          echo "🏥 Performing enhanced health check with retry logic..."
          
          # Check direct bucket access first
          BUCKET_URL="https://storage.googleapis.com/${{ env.FRONTEND_BUCKET }}/index.html"
          CDN_URL="https://clc.bunklogs.net"
          
          echo "🔍 Testing direct bucket access..."
          if curl -f -s "$BUCKET_URL" > /dev/null; then
            echo "✅ Direct bucket access successful"
          else
            echo "❌ Direct bucket access failed - deployment issue!"
            exit 1
          fi
          
          echo "🔍 Testing CDN access with retry..."
          for i in {1..5}; do
            echo "Attempt $i/5..."
            if curl -f -s "$CDN_URL" > /dev/null; then
              echo "✅ CDN access successful on attempt $i"
              break
            elif [ $i -eq 5 ]; then
              echo "⚠️ CDN access failed after 5 attempts"
              echo "📋 Manual verification may be needed"
              echo "🌐 Direct URL (backup): $BUCKET_URL"
            else
              echo "⏳ Waiting 15 seconds before retry..."
              sleep 15
            fi
          done
          
          echo ""
          echo "🚀 Frontend Deployment Summary:"
          echo "   Bucket: gs://${{ env.FRONTEND_BUCKET }}"
          echo "   Direct URL: $BUCKET_URL"
          echo "   CDN URL: $CDN_URL"
          echo ""
          echo "📝 If you still see a black screen:"
          echo "   1. Wait 2-3 minutes for global CDN propagation"
          echo "   2. Try hard refresh (Ctrl+Shift+R or Cmd+Shift+R)"
          echo "   3. Use direct bucket URL as fallback"
          echo "   4. Check browser dev tools for 404 errors on assets"